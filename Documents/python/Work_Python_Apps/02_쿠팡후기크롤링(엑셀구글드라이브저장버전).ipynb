{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d5c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿠팡후기크롤링(엑셀구글드라이브저장버전)\n",
    "\n",
    "\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, JavascriptException\n",
    "import pyautogui  # 새로 추가된 라이브러리\n",
    "\n",
    "# Google Drive API 관련 라이브러리\n",
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "import pickle\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    return webdriver.Chrome(options=options)\n",
    "\n",
    "def safe_find_text(element, by, value, default=\"-\"):\n",
    "    try:\n",
    "        found_element = element.find_element(by, value)\n",
    "        return found_element.text if found_element else default\n",
    "    except NoSuchElementException:\n",
    "        return default\n",
    "\n",
    "def scrape_review(driver, review_element, index):\n",
    "    review_data = {'순번': index + 1}\n",
    "    \n",
    "    logger.info(\"리뷰를 스크래핑하고 있습니다...\")\n",
    "\n",
    "    # 리뷰어 이름\n",
    "    review_data['리뷰어_이름'] = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__info__user__name\")\n",
    "\n",
    "    # 리뷰어 배지 (예: Vine 프로그램)\n",
    "    reviewer_badge = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__info__adventure-badge\")\n",
    "    review_data['체험단_리뷰어'] = 'VINE' in reviewer_badge\n",
    "\n",
    "    # 별점\n",
    "    star_element = review_element.find_element(By.CSS_SELECTOR, \".sdp-review__article__list__info__product-info__star-orange\")\n",
    "    style = star_element.get_attribute(\"style\") if star_element else \"\"\n",
    "    width = style.split(\"width:\")[1].split(\"%\")[0] if \"width:\" in style else \"0\"\n",
    "    review_data['평점'] = float(width) / 20 if width else \"-\"\n",
    "\n",
    "    # 리뷰 날짜 (yyyy.mm.dd -> yyyy-mm-dd 형식으로 변경)\n",
    "    original_date = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__info__product-info__reg-date\")\n",
    "    review_data['날짜'] = original_date.replace('.', '-') if original_date != \"-\" else original_date\n",
    "\n",
    "    # 판매자 이름\n",
    "    review_data['판매자_이름'] = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__info__product-info__seller_name\")\n",
    "\n",
    "    # 제품명\n",
    "    review_data['제품명'] = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__info__product-info__name\")\n",
    "\n",
    "    # 리뷰 제목\n",
    "    review_data['리뷰제목'] = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__headline\")\n",
    "\n",
    "    # 리뷰 내용\n",
    "    review_data['리뷰내용'] = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__review__content\")\n",
    "\n",
    "    # 도움이 된 수\n",
    "    review_data['도움됨_수'] = safe_find_text(review_element, By.CSS_SELECTOR, \".js_reviewArticleHelpfulCount\")\n",
    "\n",
    "    logger.info(\"이 리뷰의 스크래핑을 완료했습니다.\")\n",
    "    return review_data\n",
    "\n",
    "def scrape_reviews(url, reviews_to_crawl, filename_base, sort_option):\n",
    "    if \"www.coupang.com\" not in url:\n",
    "        logger.error(\"잘못된 URL입니다. www.coupang.com이 포함된 URL을 입력하세요.\")\n",
    "        return []\n",
    "\n",
    "    driver = setup_driver()\n",
    "    driver.get(url)\n",
    "    reviews = []\n",
    "    current_page = 1\n",
    "    reviews_per_page = 5\n",
    "    pages_to_crawl = -(-reviews_to_crawl // reviews_per_page)\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(driver, 60).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "        \n",
    "        review_tab_script = \"\"\"\n",
    "        const reviewTab = document.querySelector('#pdpReviewContentTab, #btfTab > ul.tab-titles > li:nth-child(2)');\n",
    "        if (reviewTab) {\n",
    "            reviewTab.click();\n",
    "            return true;\n",
    "        }\n",
    "        return false;\n",
    "        \"\"\"\n",
    "        is_clicked = driver.execute_script(review_tab_script)\n",
    "        \n",
    "        if not is_clicked:\n",
    "            logger.error(\"리뷰 탭을 찾을 수 없습니다.\")\n",
    "            return reviews\n",
    "        \n",
    "        if sort_option == 2:\n",
    "            logger.info(\"최신순 버튼을 클릭하고 있습니다...\")\n",
    "            try:\n",
    "                newest_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, \".sdp-review__article__order__sort__newest-btn.js_reviewArticleNewListBtn.js_reviewArticleSortBtn\"))\n",
    "                )\n",
    "                newest_button.click()\n",
    "                time.sleep(2)\n",
    "            except TimeoutException:\n",
    "                logger.warning(\"최신순 버튼을 찾을 수 없습니다. 기본 정렬 순서로 진행합니다.\")\n",
    "        \n",
    "        retry_count = 0\n",
    "        while len(reviews) < reviews_to_crawl and current_page <= pages_to_crawl:\n",
    "            try:\n",
    "                WebDriverWait(driver, 30).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \".sdp-review__article__list\"))\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                if retry_count < 3:  # 최대 3번 재시도\n",
    "                    logger.warning(\"리뷰를 찾을 수 없습니다. Page Down을 시도합니다.\")\n",
    "                    for _ in range(7):\n",
    "                        pyautogui.press('pgdn')\n",
    "                        time.sleep(0.5)\n",
    "                    retry_count += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    logger.error(\"리뷰를 찾을 수 없습니다. 다음 URL로 넘어갑니다.\")\n",
    "                    return reviews\n",
    "\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "\n",
    "            review_elements = driver.find_elements(By.CSS_SELECTOR, \".sdp-review__article__list\")\n",
    "            logger.info(f\"페이지 {current_page}: {len(review_elements)}개의 리뷰를 찾았습니다\")\n",
    "\n",
    "            page_reviews = [scrape_review(driver, review_element, i + len(reviews)) for i, review_element in enumerate(review_elements)]\n",
    "            reviews.extend(page_reviews[:reviews_to_crawl - len(reviews)])\n",
    "\n",
    "            if len(reviews) % 100 == 0:\n",
    "                save_to_csv(reviews, f\"{filename_base}_중간저장_{len(reviews)}개.csv\")\n",
    "                logger.info(f\"{len(reviews)}개의 리뷰가 중간 저장되었습니다.\")\n",
    "\n",
    "            if len(reviews) < reviews_to_crawl and current_page < pages_to_crawl:\n",
    "                try:\n",
    "                    if current_page % 10 == 0:\n",
    "                        next_button = WebDriverWait(driver, 10).until(\n",
    "                            EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.sdp-review__article__page__next'))\n",
    "                        )\n",
    "                    else:\n",
    "                        next_button = WebDriverWait(driver, 10).until(\n",
    "                            EC.element_to_be_clickable((By.CSS_SELECTOR, f'button.sdp-review__article__page__num[data-page=\"{current_page + 1}\"]'))\n",
    "                        )\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    current_page += 1\n",
    "                    time.sleep(3)\n",
    "                except (NoSuchElementException, TimeoutException) as e:\n",
    "                    logger.info(f\"더 이상 페이지가 없습니다. 페이지 {current_page}에서 중지합니다. 오류: {str(e)}\")\n",
    "                    break\n",
    "            else:\n",
    "                logger.info(f\"지정된 리뷰 수({reviews_to_crawl})에 도달했습니다\")\n",
    "                break\n",
    "\n",
    "    except TimeoutException as e:\n",
    "        logger.error(f\"페이지 로딩 시간이 초과되었습니다: {str(e)}\")\n",
    "    except JavascriptException as e:\n",
    "        logger.error(f\"JavaScript 실행 중 오류가 발생했습니다: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"스크래핑 중 오류가 발생했습니다: {str(e)}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return reviews[:reviews_to_crawl]\n",
    "\n",
    "def save_to_csv(reviews, filename):\n",
    "    df = pd.DataFrame(reviews)\n",
    "    df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "    logger.info(f\"리뷰가 {filename} 파일로 저장되었습니다.\")\n",
    "\n",
    "def open_file(filename):\n",
    "    if sys.platform.startswith('darwin'):  # macOS\n",
    "        subprocess.call(('open', filename))\n",
    "    elif sys.platform.startswith('win'):  # Windows\n",
    "        os.startfile(filename)\n",
    "    else:  # linux\n",
    "        subprocess.call(('xdg-open', filename))\n",
    "\n",
    "def upload_to_google_drive(file_path, folder_id):\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
    "    creds = None\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "\n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    file_metadata = {'name': os.path.basename(file_path), 'parents': [folder_id]}\n",
    "    media = MediaFileUpload(file_path, resumable=True)\n",
    "    file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "    logger.info(f\"파일이 구글 드라이브에 업로드되었습니다. File ID: {file.get('id')}\")\n",
    "\n",
    "def process_excel_input(excel_file):\n",
    "    df = pd.read_excel(excel_file)\n",
    "    \n",
    "    # 엑셀 파일의 실제 열 이름을 출력\n",
    "    print(\"엑셀 파일의 열 이름:\", df.columns.tolist())\n",
    "    \n",
    "    # 열 이름 매핑 (필요한 경우 수정)\n",
    "    column_mapping = {\n",
    "        'URL': 'URL',  # 예: 엑셀의 'URL' 열은 그대로 'URL'\n",
    "        '크롤링할 리뷰 수': '크롤링할 리뷰수',  # 예: 엑셀의 '크롤링할 리뷰 수' 열\n",
    "        '파일 이름': '파일 이름',  # 예: 엑셀의 '파일 이름' 열\n",
    "        '정렬 옵션': '정렬 옵션'  # 예: 엑셀의 '정렬 옵션' 열\n",
    "    }\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        url = row[column_mapping['URL']]\n",
    "        reviews_to_crawl = int(row[column_mapping['크롤링할 리뷰 수']])\n",
    "        filename_base = row[column_mapping['파일 이름']]\n",
    "        sort_option = int(row[column_mapping['정렬 옵션']])\n",
    "\n",
    "        if \"www.coupang.com\" not in url:\n",
    "            logger.error(f\"행 {index+2}: 잘못된 URL입니다. www.coupang.com이 포함된 URL을 입력하세요.\")\n",
    "            continue\n",
    "\n",
    "        today_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "        filename = f\"{filename_base}_쿠팡후기_{'베스트순' if sort_option == 1 else '최신순'}_{today_date}.csv\"\n",
    "\n",
    "        scraped_reviews = scrape_reviews(url, reviews_to_crawl, filename_base, sort_option)\n",
    "\n",
    "        if scraped_reviews:\n",
    "            save_to_csv(scraped_reviews, filename)\n",
    "            \n",
    "            # Google Drive 업로드\n",
    "            GOOGLE_DRIVE_FOLDER_ID = \"11gWrvD22k-C_DDRedXQevZWnZ7bbN7Iv\"  # 실제 폴더 ID로 변경해야 함\n",
    "            try:\n",
    "                upload_to_google_drive(filename, GOOGLE_DRIVE_FOLDER_ID)\n",
    "                logger.info(f\"파일 {filename}이 성공적으로 구글 드라이브에 업로드되었습니다.\")\n",
    "                \n",
    "                # 로컬 파일 삭제\n",
    "                os.remove(filename)\n",
    "                logger.info(f\"로컬 파일 {filename}이 삭제되었습니다.\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"구글 드라이브 업로드 중 오류가 발생했습니다: {str(e)}\")\n",
    "        else:\n",
    "            logger.error(f\"행 {index+2}: 리뷰를 스크래핑하지 못했습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    excel_file = input(\"크롤링할 정보가 담긴 엑셀 파일 이름을 입력하세요: \")\n",
    "    process_excel_input(excel_file)\n",
    "    \n",
    "    # 크롤링할 엑셀 \n",
    "    # C:\\Users\\owner\\Documents\\python\\엑셀업로드양식(쿠팡).xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af0818d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'finally' statement on line 175 (203942631.py, line 179)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 179\u001b[1;36m\u001b[0m\n\u001b[1;33m    return reviews[:reviews_to_crawl]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'finally' statement on line 175\n"
     ]
    }
   ],
   "source": [
    "# 쿠팡크롤링 통합 버전 (구글드라이브 저장)\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, JavascriptException\n",
    "\n",
    "# Google Drive API 관련 라이브러리 추가\n",
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "import pickle\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    return webdriver.Chrome(options=options)\n",
    "\n",
    "def safe_find_text(element, by, value, default=\"-\"):\n",
    "    try:\n",
    "        found_element = element.find_element(by, value)\n",
    "        return found_element.text if found_element else default\n",
    "    except NoSuchElementException:\n",
    "        return default\n",
    "\n",
    "def scrape_review(driver, review_element, index):\n",
    "    review_data = {'순번': index + 1}\n",
    "    \n",
    "    logger.info(\"리뷰를 스크래핑하고 있습니다...\")\n",
    "\n",
    "    # 리뷰어 이름\n",
    "    review_data['리뷰어_이름'] = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__info__user__name\")\n",
    "\n",
    "    # 리뷰어 배지 (예: Vine 프로그램)\n",
    "    reviewer_badge = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__info__adventure-badge\")\n",
    "    review_data['체험단_리뷰어'] = 'VINE' in reviewer_badge\n",
    "\n",
    "    # 별점\n",
    "    star_element = review_element.find_element(By.CSS_SELECTOR, \".sdp-review__article__list__info__product-info__star-orange\")\n",
    "    style = star_element.get_attribute(\"style\") if star_element else \"\"\n",
    "    width = style.split(\"width:\")[1].split(\"%\")[0] if \"width:\" in style else \"0\"\n",
    "    review_data['평점'] = float(width) / 20 if width else \"-\"\n",
    "\n",
    "    # 리뷰 날짜 (yyyy.mm.dd -> yyyy-mm-dd 형식으로 변경)\n",
    "    original_date = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__info__product-info__reg-date\")\n",
    "    review_data['날짜'] = original_date.replace('.', '-') if original_date != \"-\" else original_date\n",
    "\n",
    "    # 판매자 이름\n",
    "    review_data['판매자_이름'] = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__info__product-info__seller_name\")\n",
    "\n",
    "    # 제품명\n",
    "    review_data['제품명'] = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__info__product-info__name\")\n",
    "\n",
    "    # 리뷰 제목\n",
    "    review_data['리뷰제목'] = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__headline\")\n",
    "\n",
    "    # 리뷰 내용\n",
    "    review_data['리뷰내용'] = safe_find_text(review_element, By.CSS_SELECTOR, \".sdp-review__article__list__review__content\")\n",
    "\n",
    "    # 도움이 된 수\n",
    "    review_data['도움됨_수'] = safe_find_text(review_element, By.CSS_SELECTOR, \".js_reviewArticleHelpfulCount\")\n",
    "\n",
    "    logger.info(\"이 리뷰의 스크래핑을 완료했습니다.\")\n",
    "    return review_data\n",
    "\n",
    "def scrape_reviews(url, reviews_to_crawl, filename_base, sort_option):\n",
    "    # URL 유효성 체크\n",
    "    if \"www.coupang.com\" not in url:\n",
    "        logger.error(\"잘못된 URL입니다. www.coupang.com이 포함된 URL을 입력하세요.\")\n",
    "        return []\n",
    "\n",
    "    driver = setup_driver()\n",
    "    driver.get(url)\n",
    "    reviews = []\n",
    "    current_page = 1\n",
    "    reviews_per_page = 5  # 쿠팡의 경우 한 페이지당 5개의 리뷰가 있습니다\n",
    "    pages_to_crawl = -(-reviews_to_crawl // reviews_per_page)  # 올림 나눗셈\n",
    "\n",
    "    try:\n",
    "        # 페이지가 완전히 로드될 때까지 대기\n",
    "        WebDriverWait(driver, 60).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "        \n",
    "        # 리뷰 탭 클릭\n",
    "        review_tab_script = \"\"\"\n",
    "        const reviewTab = document.querySelector('#pdpReviewContentTab, #btfTab > ul.tab-titles > li:nth-child(2)');\n",
    "        if (reviewTab) {\n",
    "            reviewTab.click();\n",
    "            return true;\n",
    "        }\n",
    "        return false;\n",
    "        \"\"\"\n",
    "        is_clicked = driver.execute_script(review_tab_script)\n",
    "        \n",
    "        if not is_clicked:\n",
    "            logger.error(\"리뷰 탭을 찾을 수 없습니다.\")\n",
    "            return reviews\n",
    "        \n",
    "        # 정렬 옵션 선택\n",
    "        if sort_option == 2:  # 최신순\n",
    "            logger.info(\"최신순 버튼을 클릭하고 있습니다...\")\n",
    "            try:\n",
    "                newest_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, \".sdp-review__article__order__sort__newest-btn.js_reviewArticleNewListBtn.js_reviewArticleSortBtn\"))\n",
    "                )\n",
    "                newest_button.click()\n",
    "                time.sleep(2)\n",
    "            except TimeoutException:\n",
    "                logger.warning(\"최신순 버튼을 찾을 수 없습니다. 기본 정렬 순서로 진행합니다.\")\n",
    "        \n",
    "        while len(reviews) < reviews_to_crawl and current_page <= pages_to_crawl:\n",
    "            WebDriverWait(driver, 30).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \".sdp-review__article__list\"))\n",
    "            )\n",
    "            \n",
    "            # 스크롤 다운\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "\n",
    "            review_elements = driver.find_elements(By.CSS_SELECTOR, \".sdp-review__article__list\")\n",
    "            logger.info(f\"페이지 {current_page}: {len(review_elements)}개의 리뷰를 찾았습니다\")\n",
    "\n",
    "            # 순번 추가\n",
    "            page_reviews = [scrape_review(driver, review_element, i + len(reviews)) for i, review_element in enumerate(review_elements)]\n",
    "            reviews.extend(page_reviews[:reviews_to_crawl - len(reviews)])  # 필요한 만큼만 추가\n",
    "\n",
    "            if len(reviews) % 100 == 0:\n",
    "                save_to_csv(reviews, f\"{filename_base}_중간저장_{len(reviews)}개.csv\")\n",
    "                logger.info(f\"{len(reviews)}개의 리뷰가 중간 저장되었습니다.\")\n",
    "\n",
    "            if len(reviews) < reviews_to_crawl and current_page < pages_to_crawl:\n",
    "                try:\n",
    "                    if current_page % 10 == 0:\n",
    "                        next_button = WebDriverWait(driver, 10).until(\n",
    "                            EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.sdp-review__article__page__next'))\n",
    "                        )\n",
    "                    else:\n",
    "                        next_button = WebDriverWait(driver, 10).until(\n",
    "                            EC.element_to_be_clickable((By.CSS_SELECTOR, f'button.sdp-review__article__page__num[data-page=\"{current_page + 1}\"]'))\n",
    "                        )\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    current_page += 1\n",
    "                    time.sleep(3)\n",
    "                except (NoSuchElementException, TimeoutException) as e:\n",
    "                    logger.info(f\"더 이상 페이지가 없습니다. 페이지 {current_page}에서 중지합니다. 오류: {str(e)}\")\n",
    "                    break\n",
    "            else:\n",
    "                logger.info(f\"지정된 리뷰 수({reviews_to_crawl})에 도달했습니다\")\n",
    "                break\n",
    "\n",
    "    except TimeoutException as e:\n",
    "        logger.error(f\"페이지 로딩 시간이 초과되었습니다: {str(e)}\")\n",
    "    except JavascriptException as e:\n",
    "        logger.error(f\"JavaScript 실행 중 오류가 발생했습니다: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"스크래핑 중 오류가 발생했습니다: {str(e)}\")\n",
    "    finally:\n",
    "        \n",
    "        # driver.quit()\n",
    "        pass\n",
    "\n",
    "    return reviews[:reviews_to_crawl]\n",
    "\n",
    "def save_to_csv(reviews, filename):\n",
    "    df = pd.DataFrame(reviews)\n",
    "    df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "    logger.info(f\"리뷰가 {filename} 파일로 저장되었습니다.\")\n",
    "\n",
    "def open_file(filename):\n",
    "    if sys.platform.startswith('darwin'):  # macOS\n",
    "        subprocess.call(('open', filename))\n",
    "    elif sys.platform.startswith('win'):  # Windows\n",
    "        os.startfile(filename)\n",
    "    else:  # linux\n",
    "        subprocess.call(('xdg-open', filename))\n",
    "\n",
    "# Google Drive 업로드 함수\n",
    "def upload_to_google_drive(file_path, folder_id):\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
    "    creds = None\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "\n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    file_metadata = {'name': os.path.basename(file_path), 'parents': [folder_id]}\n",
    "    media = MediaFileUpload(file_path, resumable=True)\n",
    "    file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "    logger.info(f\"파일이 구글 드라이브에 업로드되었습니다. File ID: {file.get('id')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = input(\"크롤링할 상품 URL을 입력하세요: \")\n",
    "    if \"www.coupang.com\" not in url:\n",
    "        print(\"잘못된 URL입니다. www.coupang.com이 포함된 URL을 입력하세요.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    reviews_to_crawl = int(input(\"크롤링할 리뷰 수를 입력하세요: \"))\n",
    "    filename_base = input(\"저장할 파일 이름을 입력하세요 (확장자 제외): \")\n",
    "    sort_option = int(input(\"정렬 옵션을 선택하세요 (1: 베스트순, 2: 최신순): \"))\n",
    "    \n",
    "    today_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "    filename = f\"{filename_base}_쿠팡후기_{'베스트순' if sort_option == 1 else '최신순'}_{today_date}.csv\"\n",
    "    \n",
    "    scraped_reviews = scrape_reviews(url, reviews_to_crawl, filename_base, sort_option)\n",
    "\n",
    "    if scraped_reviews:\n",
    "        save_to_csv(scraped_reviews, filename)\n",
    "        open_file(filename)\n",
    "        \n",
    "        # Google Drive 업로드\n",
    "        GOOGLE_DRIVE_FOLDER_ID = \"11gWrvD22k-C_DDRedXQevZWnZ7bbN7Iv\"  # 여기에 실제 폴더 ID를 입력하세요\n",
    "        try:\n",
    "            upload_to_google_drive(filename, GOOGLE_DRIVE_FOLDER_ID)\n",
    "            logger.info(\"파일이 성공적으로 구글 드라이브에 업로드되었습니다.\")\n",
    "            \n",
    "             # 로컬 파일 삭제\n",
    "            os.remove(filename)\n",
    "            logger.info(f\"로컬 파일 {filename}이 삭제되었습니다.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"구글 드라이브 업로드 중 오류가 발생했습니다: {str(e)}\")\n",
    "    else:\n",
    "        print(\"리뷰를 스크래핑하지 못했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5582e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
