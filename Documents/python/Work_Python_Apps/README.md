# Work Python Apps

Python을 활용한 웹 크롤링 및 데이터 수집 자동화 프로그램 모음입니다.

## 📋 목차

- [개요](#개요)
- [주요 기능](#주요-기능)
- [설치 및 설정](#설치-및-설정)
- [프로그램 목록](#프로그램-목록)
- [사용법](#사용법)
- [주의사항](#주의사항)

## 개요

이 프로젝트는 네이버, 쿠팡 등 주요 쇼핑몰의 상품 리뷰, 검색어 데이터를 자동으로 수집하고 분석하는 Python 프로그램들을 포함합니다. Selenium을 활용한 웹 크롤링과 Google Drive API를 통한 자동 저장 기능을 제공합니다.

## 주요 기능

- 🛒 **쇼핑몰 리뷰 크롤링**: 네이버 스마트스토어, 쿠팡 상품 리뷰 자동 수집
- 📊 **데이터랩 검색어 수집**: 네이버 데이터랩 인기 검색어 자동 수집
- ☁️ **구글 드라이브 자동 저장**: 수집한 데이터를 구글 드라이브에 자동 업로드
- 📈 **엑셀 자동 저장**: 수집한 데이터를 엑셀 파일로 자동 저장
- 🖱️ **자동화 도구**: 좌표 감지 및 자동 클릭 프로그램
- 🚀 **스크립트 실행기**: GUI 기반 프로그램 실행 도구

## 설치 및 설정

### 필수 라이브러리

```bash
pip install selenium pandas openpyxl webdriver-manager google-api-python-client google-auth-httplib2 google-auth-oauthlib opencv-python pyautogui tkinter
```

### Google Drive API 설정

1. Google Cloud Console에서 프로젝트 생성
2. Google Drive API 활성화
3. OAuth 2.0 클라이언트 ID 생성
4. `client_secret.json` 파일을 프로젝트 루트에 배치
5. 프로그램 실행 시 인증 토큰 자동 생성 (`token.json`)

### ChromeDriver

프로그램은 `webdriver-manager`를 사용하여 ChromeDriver를 자동으로 설치합니다.

## 프로그램 목록

### 네이버 관련 프로그램

#### 00_네이버후기크롤링(구글드라이브저장버전).ipynb
- **기능**: 네이버 스마트스토어 상품 리뷰 크롤링 및 구글 드라이브 자동 저장
- **입력**: 상품 URL, 파일명, 정렬 방식(랭킹순/최신순/평점순), 최대 리뷰 수
- **출력**: CSV 파일 (구글 드라이브 자동 업로드)
- **특징**: 
  - 100개 리뷰마다 중간 저장
  - 정렬 옵션 지원 (랭킹순, 최신순, 평점 높은순, 평점 낮은순)
  - 자동 페이지네이션 처리

#### 00_스마트스토어후기크롤링(엑셀구글드라이브저장 버전).ipynb
- **기능**: 네이버 스마트스토어 상품 페이지의 리뷰를 자동으로 수집하고, 엑셀 파일로 구글 드라이브에 자동 업로드
- **주요 기능**:
  - 네이버 스마트스토어 상품 리뷰 자동 수집
  - 엑셀 파일 형식으로 저장
  - 구글 드라이브 자동 업로드
  - 리뷰 정렬 옵션 지원
- **사용 방법**: 상품 URL 입력 → 저장할 파일 이름 입력 → 정렬 방식 선택 → 크롤링할 최대 리뷰 수 입력
- **필요 라이브러리**: selenium, pandas, openpyxl, google-api-python-client
- **주의사항**: Google Drive API 인증이 필요합니다 (client_secret.json 파일 필요)

#### 4_스마트스토어후기크롤링.ipynb
- **기능**: 네이버 스마트스토어 상품 페이지의 리뷰를 자동으로 수집하고 로컬에 CSV 파일로 저장
- **주요 기능**:
  - 네이버 스마트스토어 상품 리뷰 자동 수집
  - 로컬 CSV 파일 저장
  - 리뷰 정보 수집 (평점, 구매자 아이디, 날짜, 선택 옵션명, 리뷰 내용)
- **사용 방법**: 상품 페이지 URL 입력 → 저장할 CSV 파일 이름 입력 → 크롤링할 최대 리뷰 수 입력
- **필요 라이브러리**: selenium, pandas, webdriver-manager
- **주의사항**: 네이버 웹사이트 구조 변경 시 수정이 필요할 수 있습니다

#### 00_데이타랩개별스트랩핑.ipynb
- **기능**: 네이버 데이터랩 인기 검색어 개별 수집
- **입력**: 저장할 파일명
- **출력**: 엑셀 파일 (순위, 인기검색어, 기간, 분야 정보)
- **특징**: 500개 검색어 자동 수집 (25페이지)

#### 00_도매꾹_베스트상품크롤링.ipynb
- **기능**: 도매꾹 웹사이트에서 카테고리별 베스트 상품 정보를 자동으로 수집하고 구글 드라이브에 업로드
- **주요 기능**:
  - 도매꾹 카테고리별 베스트 상품 정보 수집
  - 구글 드라이브 자동 업로드
  - 여러 카테고리 지원 (전체, 패션잡화, 의류, 출산/유아동, 가구/생활, 스포츠/건강, 가전/휴대폰)
- **출력**: CSV 파일 (구글 드라이브 자동 업로드)
- **필요 라이브러리**: beautifulsoup4, pandas, requests, google-api-python-client
- **주의사항**: Google Drive API 인증이 필요합니다 (client_secret.json 파일 필요)

#### 00_열별카테고리구분하여저장하기.ipynb
- **기능**: 엑셀 파일의 특정 열을 기준으로 데이터를 카테고리별로 분류하여 각각 별도의 엑셀 파일로 저장
- **주요 기능**:
  - 엑셀 파일의 특정 열을 기준으로 데이터 분류
  - 카테고리별로 별도 엑셀 파일 생성
  - GUI를 통한 파일 및 폴더 선택
  - 특수 문자 자동 제거 (파일명 안전성)
- **사용 방법**: 원본 엑셀 파일 선택 → 분류할 열 번호 입력 → 파일명 접두사 입력 → 저장할 폴더 선택
- **필요 라이브러리**: pandas, openpyxl, tkinter
- **주의사항**: 열 번호는 1부터 시작합니다

#### 03_데이타랩인기검색어설정.ipynb
- **기능**: 네이버 데이터랩에서 카테고리를 선택하고 인기 검색어를 수집하여 엑셀 파일로 저장
- **주요 기능**:
  - 네이버 데이터랩 카테고리 선택 (분야1, 분야2 등)
  - 인기 검색어 자동 수집
  - 엑셀 파일 자동 저장 (날짜 포함)
  - 검색어 순위 정보 수집
- **사용 방법**: 저장할 엑셀 파일 기본 이름 입력 → 브라우저에서 카테고리 선택 → 자동으로 검색어 수집 및 엑셀 저장
- **필요 라이브러리**: selenium, openpyxl, requests
- **주의사항**: 카테고리는 브라우저에서 수동으로 선택해야 합니다

#### 네이버데이타랩검색_검색량포함.ipynb
- **기능**: 네이버 데이터랩과 네이버 광고 API를 활용하여 검색어와 검색량을 함께 수집하고 엑셀 파일로 저장
- **주요 기능**:
  - 네이버 데이터랩에서 검색어 수집
  - 네이버 광고 API로 검색량 조회
  - Selenium을 활용한 웹 크롤링
  - 엑셀 파일 자동 저장
- **사용 방법**: 검색어 입력 → 자동으로 검색어 및 검색량 수집 → 엑셀 저장
- **필요 라이브러리**: selenium, requests, pandas, openpyxl
- **주의사항**: 네이버 광고 API 키가 필요합니다

#### 네이버데이터랩검색어500.ipynb
- **기능**: 네이버 데이터랩에서 500개 검색어 수집
- **출력**: 500개 검색어 리스트

#### 네이버블로그발행정보_최신순.ipynb
- **기능**: 네이버 블로그 검색 API를 사용하여 특정 키워드에 대한 최신 블로그 포스트 정보를 수집하고 엑셀 파일로 저장
- **주요 기능**:
  - 네이버 블로그 검색 API 활용
  - 최신순 블로그 포스트 수집
  - 블로그 제목, 링크, 설명, 발행일 등 정보 수집
  - 엑셀 파일 자동 저장
- **사용 방법**: 검색어 입력 → 수집할 포스트 수 입력 → 자동으로 수집 및 엑셀 저장
- **필요 라이브러리**: requests, pandas, openpyxl
- **주의사항**: 네이버 블로그 검색 API 키가 필요합니다

#### 네이버쇼핑검색.ipynb
- **기능**: 네이버 쇼핑 검색 API를 사용하여 상품 정보를 검색하고 엑셀 파일로 저장하는 프로그램 (콘솔 버전)
- **주요 기능**:
  - 네이버 쇼핑 검색 API 활용
  - 상품 정보 자동 수집 (제목, 가격, 링크, 카테고리 등)
  - 엑셀 파일 자동 저장 (날짜 포함)
  - 환경 변수를 통한 API 키 관리
- **사용 방법**: 환경 변수에 NAVER_CLIENT_ID, NAVER_CLIENT_SECRET 설정 → 프로그램 실행 → 검색어 입력 → 검색 결과 개수 입력 → 저장할 파일명 입력
- **필요 라이브러리**: requests, pandas, openpyxl
- **주의사항**: 네이버 API 키가 필요합니다 (환경 변수로 설정), API 사용량 제한이 있을 수 있습니다

#### 네이버쇼핑검색API.ipynb
- **기능**: 네이버 쇼핑 검색 API를 사용하여 상품 정보를 검색하고 엑셀 파일로 저장하는 프로그램 (Tkinter GUI 버전)
- **주요 기능**:
  - 네이버 쇼핑 검색 API 활용
  - GUI 인터페이스 제공
  - 상품 정보 자동 수집 (제목, 가격, 링크 등)
  - 엑셀 파일 자동 저장 (날짜 포함)
  - 환경 변수를 통한 API 키 관리
- **사용 방법**: 환경 변수에 NAVER_CLIENT_ID, NAVER_CLIENT_SECRET 설정 → 프로그램 실행 → 검색어 입력 → 검색 결과 건수 입력
- **필요 라이브러리**: requests, pandas, tkinter
- **주의사항**: 네이버 API 키가 필요합니다 (환경 변수로 설정), API 사용량 제한이 있을 수 있습니다

#### 네이버월간검색량.ipynb
- **기능**: 네이버 광고 API를 사용하여 키워드의 월간 검색량을 조회하는 Tkinter GUI 프로그램
- **주요 기능**:
  - 네이버 광고 API 활용
  - 키워드 월간 검색량 조회
  - Tkinter GUI 인터페이스
  - 엑셀 파일 저장
- **사용 방법**: GUI에서 키워드 입력 → 검색량 조회 → 엑셀 저장
- **필요 라이브러리**: requests, pandas, tkinter
- **주의사항**: 네이버 광고 API 키가 필요합니다

#### 네이버월간검색량조회및엑셀업데이트.ipynb
- **기능**: 네이버 광고 API를 사용하여 키워드의 월간 검색량을 조회하고 기존 엑셀 파일을 자동으로 업데이트
- **주요 기능**:
  - 네이버 광고 API 활용
  - 키워드 월간 검색량 조회
  - 기존 엑셀 파일 자동 업데이트
- **사용 방법**: 엑셀 파일 경로 입력 → 키워드 검색량 조회 및 업데이트
- **필요 라이브러리**: requests, pandas, openpyxl
- **주의사항**: 네이버 광고 API 키가 필요합니다

#### 네이버키워드검색어추이.ipynb
- **기능**: 네이버 데이터랩 API를 사용하여 최대 5개의 키워드에 대한 검색어 추이를 분석하고 시각화하는 Tkinter GUI 프로그램
- **주요 기능**:
  - 네이버 데이터랩 API 활용
  - 최대 5개 키워드 검색어 추이 분석
  - 그래프 시각화
  - Tkinter GUI 인터페이스
  - 엑셀 파일 저장
- **사용 방법**: GUI에서 키워드 입력 (최대 5개) → 기간 설정 → 검색어 추이 분석 및 시각화
- **필요 라이브러리**: requests, pandas, matplotlib, tkinter
- **주의사항**: 네이버 데이터랩 API 키가 필요합니다

#### 네이타랩전체검색어조회하기.ipynb
- **기능**: 네이버 데이터랩에서 전체 검색어를 조회하고 엑셀 파일로 저장
- **주요 기능**:
  - 네이버 데이터랩 전체 검색어 수집
  - 엑셀 파일 자동 저장
  - Selenium을 활용한 웹 크롤링
- **사용 방법**: 프로그램 실행 → 자동으로 전체 검색어 수집 → 엑셀 저장
- **필요 라이브러리**: selenium, pandas, openpyxl
- **주의사항**: 네이버 데이터랩 페이지 구조 변경 시 수정이 필요할 수 있습니다

#### 데이타랩_분야1_전체자동스크랩핑(구글드라이브저장버전).ipynb
- **기능**: 네이버 데이터랩 분야1 전체 자동 스크래핑 및 구글 드라이브 저장
- **출력**: 구글 드라이브 자동 업로드

#### 데이타랩_분야2_전체자동스크랩핑(구글드라이브저장버전).ipynb
- **기능**: 네이버 데이터랩 분야2 전체 자동 스크래핑 및 구글 드라이브 저장
- **출력**: 구글 드라이브 자동 업로드

#### 데이타랩검색어500_사용자로코드입력받음.ipynb
- **기능**: 사용자로부터 네이버 데이터랩 카테고리 코드를 입력받아 해당 카테고리의 인기 검색어 500개를 수집하고 엑셀 파일로 저장
- **주요 기능**:
  - 사용자 입력 코드 기반 카테고리 선택
  - 인기 검색어 500개 자동 수집
  - 엑셀 파일 자동 저장
- **사용 방법**: 카테고리 코드 입력 → 자동으로 500개 검색어 수집 → 엑셀 저장
- **필요 라이브러리**: selenium, pandas, openpyxl
- **주의사항**: 올바른 카테고리 코드를 입력해야 합니다

#### 데이타랩검색어_검색량_페이지수입력.ipynb
- **기능**: 네이버 데이터랩에서 검색어, 검색량, 페이지 수를 수집하는 멀티스레딩 프로그램
- **주요 기능**:
  - 네이버 데이터랩 검색어 수집
  - 네이버 광고 API로 검색량 조회
  - 페이지 수 정보 수집
  - 멀티스레딩을 통한 빠른 처리
  - 엑셀 파일 자동 저장
- **사용 방법**: 검색어 입력 → 수집할 페이지 수 입력 → 자동으로 수집 및 엑셀 저장
- **필요 라이브러리**: selenium, requests, pandas, openpyxl, concurrent.futures
- **주의사항**: 네이버 광고 API 키가 필요합니다, 멀티스레딩 사용 시 API 사용량 제한에 주의하세요

### 쿠팡 관련 프로그램

#### 02_쿠팡후기크롤링(구글드라이브저장버전).ipynb
- **기능**: 쿠팡 상품 리뷰 크롤링 및 구글 드라이브 자동 저장
- **입력**: 상품 URL, 파일명, 정렬 방식, 최대 리뷰 수
- **출력**: CSV 파일 (구글 드라이브 자동 업로드)
- **특징**:
  - 리뷰어 정보, 평점, 날짜, 리뷰 내용 수집
  - 체험단 리뷰어 구분
  - 도움이 된 수 정보 포함

#### 02_쿠팡후기크롤링(엑셀구글드라이브저장버전).ipynb
- **기능**: 쿠팡 리뷰 크롤링 및 엑셀 파일로 구글 드라이브 저장
- **입력**: 상품 URL, 파일명, 정렬 방식, 최대 리뷰 수
- **출력**: 엑셀 파일 (구글 드라이브 자동 업로드)

#### 03_쿠팡후기크롤링.ipynb
- **기능**: 쿠팡 상품 리뷰 크롤링 (로컬 저장)
- **출력**: CSV 파일 (로컬 저장)

#### 04_쿠팡상품검색크롤링.ipynb
- **기능**: 쿠팡 상품 검색 결과 크롤링
- **입력**: 검색어, 페이지 수
- **출력**: 상품 정보 (가격, 리뷰 수, 평점 등)
- **특징**: 광고 상품 필터링 기능

#### 쿠팡거래명세서확인.ipynb
- **기능**: 쿠팡 셀러 센터에서 거래명세서 확인 프로세스를 자동화하는 프로그램
- **주요 기능**:
  - 쿠팡 셀러 센터 자동 로그인
  - 거래명세서 자동 확인
  - pyautogui를 활용한 자동화
- **사용 방법**: 프로그램 실행 → 자동으로 거래명세서 확인 프로세스 진행
- **필요 라이브러리**: selenium, pyautogui
- **주의사항**: 쿠팡 셀러 센터 구조 변경 시 수정이 필요할 수 있습니다

#### 쿠팡거래명세서확인프로그램.ipynb
- **기능**: 쿠팡 셀러 센터에서 거래명세서 확인 프로세스를 자동화하는 프로그램 (마우스 위치 확인 기능 포함)
- **주요 기능**:
  - 쿠팡 셀러 센터 자동 로그인
  - 거래명세서 자동 확인
  - 마우스 위치 확인 기능
  - pyautogui를 활용한 자동화
- **사용 방법**: 프로그램 실행 → 마우스 위치 확인 (선택) → 자동으로 거래명세서 확인 프로세스 진행
- **필요 라이브러리**: selenium, pyautogui
- **주의사항**: 쿠팡 셀러 센터 구조 변경 시 수정이 필요할 수 있습니다

#### 쿠팡세금계산서확인.ipynb
- **기능**: 쿠팡 셀러 센터에서 세금계산서 승인 프로세스를 자동화하는 프로그램
- **주요 기능**:
  - 쿠팡 셀러 센터 자동 로그인
  - 세금계산서 자동 승인
  - pyautogui를 활용한 자동화
- **사용 방법**: 프로그램 실행 → 자동으로 세금계산서 승인 프로세스 진행
- **필요 라이브러리**: selenium, pyautogui
- **주의사항**: 쿠팡 셀러 센터 구조 변경 시 수정이 필요할 수 있습니다

#### 쿠팡후기크롤링(전체_내용제외).ipynb
- **기능**: 쿠팡 상품 리뷰의 메타데이터를 수집하는 PyQt5 GUI 프로그램 (리뷰 내용 제외)
- **주요 기능**:
  - 쿠팡 상품 리뷰 메타데이터 수집 (리뷰 내용 제외)
  - PyQt5 GUI 인터페이스
  - 엑셀 파일로 저장
- **사용 방법**: GUI에서 상품 URL 입력 → 크롤링 설정 → 실행
- **필요 라이브러리**: selenium, pandas, openpyxl, PyQt5
- **주의사항**: 쿠팡 웹사이트 구조 변경 시 수정이 필요할 수 있습니다

#### 쿠팡크롤링디버깅용.ipynb
- **기능**: 쿠팡 크롤링 기능을 디버깅하고 테스트하기 위한 PyQt5 GUI 프로그램
- **주요 기능**:
  - 쿠팡 크롤링 기능 테스트
  - 디버깅 정보 출력
  - PyQt5 GUI 인터페이스
- **사용 방법**: GUI에서 테스트할 기능 선택 및 실행
- **필요 라이브러리**: selenium, PyQt5
- **주의사항**: 개발 및 디버깅 목적으로 사용됩니다

### 자동화 도구

#### 01_스크립터실행기.ipynb
- **기능**: GUI 기반 스크립트 실행기
- **입력**: `config.json` 파일에 스크립트 목록 정의
- **특징**:
  - Tkinter 기반 GUI
  - 여러 스크립트를 버튼으로 실행
  - 로그 파일 자동 생성
- **설정 파일 예시**:
```json
{
  "scripts": [
    {"name": "네이버 후기 크롤링", "path": "00_네이버후기크롤링(구글드라이브저장버전).ipynb"},
    {"name": "쿠팡 후기 크롤링", "path": "02_쿠팡후기크롤링(구글드라이브저장버전).ipynb"}
  ]
}
```

#### 자동 좌표 감지 & 자동 클릭 프로그램.ipynb
- **기능**: 이미지 매칭을 통한 자동 좌표 감지 및 클릭
- **입력**: 템플릿 이미지 경로
- **특징**:
  - OpenCV를 활용한 이미지 매칭
  - 화면에서 특정 이미지 자동 감지 및 클릭
  - 로그 출력 기능

#### 포셀바로가기.ipynb
- **기능**: 포셀 웹사이트를 기본 웹 브라우저에서 자동으로 여는 간단한 바로가기 프로그램
- **주요 기능**:
  - 포셀 웹사이트 자동 열기
  - 기본 웹 브라우저 사용
- **사용 방법**: 프로그램 실행 → 자동으로 포셀 웹사이트가 브라우저에서 열림
- **필요 라이브러리**: webbrowser (Python 표준 라이브러리)
- **주의사항**: 기본 웹 브라우저가 설정되어 있어야 합니다

### 기타 프로그램

#### 기간별 여러 채널 유튜브 정보 검색.ipynb
- **기능**: YouTube Data API를 사용하여 기간별로 여러 채널의 정보를 검색하고 분석하는 프로그램
- **주요 기능**:
  - YouTube Data API 활용
  - 기간별 채널 정보 검색
  - 여러 채널 동시 검색
  - 채널 통계 정보 수집 (구독자 수, 동영상 수 등)
  - 엑셀 파일 자동 저장
- **사용 방법**: 채널 ID 목록 입력 → 기간 설정 → 자동으로 채널 정보 수집 및 엑셀 저장
- **필요 라이브러리**: google-api-python-client, pandas, openpyxl
- **주의사항**: YouTube Data API 키가 필요합니다, API 사용량 제한이 있을 수 있습니다

#### 크롤링실습.ipynb
- **기능**: 웹 크롤링 기초를 학습하기 위한 실습 프로그램
- **주요 기능**:
  - BeautifulSoup을 활용한 HTML 파싱
  - Selenium을 활용한 동적 웹 크롤링
  - 기본적인 크롤링 기법 학습
- **사용 방법**: 실습 코드를 순서대로 실행하며 크롤링 기법 학습
- **필요 라이브러리**: beautifulsoup4, selenium, requests
- **주의사항**: 학습 목적으로 제작되었습니다

#### 크롤링프로그램.ipynb
- **기능**: 네이버 광고 API를 사용하여 키워드의 월간 검색량을 조회하는 범용 크롤링 프로그램
- **주요 기능**:
  - 네이버 광고 API 활용
  - 키워드 월간 검색량 조회
  - 데이터 수집 및 저장
- **사용 방법**: 키워드 입력 → 검색량 조회
- **필요 라이브러리**: requests, pandas
- **주의사항**: 네이버 광고 API 키가 필요합니다

## 사용법

### 기본 사용법

1. Jupyter Notebook 실행
2. 원하는 프로그램 파일 열기
3. 셀을 순서대로 실행
4. 프로그램에서 요구하는 입력값 입력 (URL, 파일명 등)
5. 결과 확인 (CSV/엑셀 파일 또는 구글 드라이브)

### 구글 드라이브 저장 프로그램 사용법

1. `client_secret.json` 파일이 프로젝트 루트에 있는지 확인
2. 프로그램 실행 시 브라우저가 열리면 Google 계정 로그인
3. 권한 승인
4. 이후 자동으로 `token.json` 생성되어 재인증 불필요

### 스크립트 실행기 사용법

1. `config.json` 파일 생성 및 스크립트 목록 작성
2. `01_스크립터실행기.ipynb` 실행
3. GUI 창에서 원하는 스크립트 버튼 클릭

## 주의사항

### 법적 고지

- 이 프로그램들은 교육 및 개인 연구 목적으로 제작되었습니다.
- 웹사이트의 이용약관을 준수하여 사용하세요.
- 과도한 요청은 IP 차단을 유발할 수 있으므로 적절한 딜레이를 설정하세요.
- 상업적 용도로 사용 시 해당 웹사이트의 정책을 확인하세요.

### 기술적 주의사항

- **민감한 정보 보호**: `client_secret.json`, `token.json`, `config.json` 파일은 절대 공개 저장소에 업로드하지 마세요.
- **ChromeDriver 버전**: Chrome 브라우저 버전과 ChromeDriver 버전이 호환되어야 합니다.
- **네트워크 안정성**: 크롤링 중 네트워크 연결이 불안정하면 오류가 발생할 수 있습니다.
- **웹사이트 구조 변경**: 웹사이트 구조가 변경되면 프로그램 수정이 필요할 수 있습니다.

### 권장 사항

- 크롤링 시 적절한 딜레이 시간 설정 (2-4초)
- 대량 데이터 수집 시 중간 저장 기능 활용
- 정기적으로 프로그램 업데이트 확인
- 로그 파일을 확인하여 오류 추적

## 파일 구조

```
Work_Python_Apps/
├── README.md                          # 프로젝트 설명서
├── .gitignore                         # Git 제외 파일 목록
├── config.json                        # 스크립트 실행기 설정 파일 (민감 정보)
├── client_secret.json                 # Google API 인증 정보 (민감 정보)
├── token.json                         # Google API 토큰 (민감 정보)
├── 00_네이버후기크롤링(...).ipynb    # 네이버 리뷰 크롤링
├── 02_쿠팡후기크롤링(...).ipynb      # 쿠팡 리뷰 크롤링
├── 01_스크립터실행기.ipynb            # 스크립트 실행기
├── images/                            # 이미지 파일 저장 폴더
│   ├── list.png
│   ├── sku.png
│   └── trans_check.png
└── ... (기타 노트북 파일들)
```

## 라이선스

이 프로젝트는 개인 사용 목적으로 제작되었습니다.

## 문의

프로그램 사용 중 문제가 발생하거나 개선 사항이 있으면 이슈를 등록해주세요.

---

**마지막 업데이트**: 2026년 1월

---

## 프로그램별 상세 정보

각 노트북 파일의 첫 번째 셀에는 프로그램에 대한 상세한 설명이 마크다운 형식으로 포함되어 있습니다. 각 프로그램의 기능, 사용 방법, 필요 라이브러리, 주의사항 등을 확인할 수 있습니다.
